{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "core/rag.py - The RAG Pipeline.\n",
        "\n",
        "This module contains the `RAGPipeline` class, which orchestrates the retrieval\n",
        "of relevant documents for a given query. It uses OpenAI embeddings and a FAISS\n",
        "vector store to perform efficient similarity searches.\n",
        "\"\"\"\n",
        "import logging\n",
        "from typing import List\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Set up logging for this module\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class RAGPipeline:\n",
        "    \"\"\"\n",
        "    Implements a Retrieval-Augmented Generation (RAG) pipeline.\n",
        "\n",
        "    This class handles the core logic for retrieving relevant knowledge from a\n",
        "    vector store to provide context for an LLM.\n",
        "    \"\"\"\n",
        "    def __init__(self, docs: List[str]):\n",
        "        \"\"\"\n",
        "        Initializes the RAG pipeline with a list of documents.\n",
        "\n",
        "        Args:\n",
        "            docs: A list of strings representing the knowledge base documents.\n",
        "        \"\"\"\n",
        "        logger.info(\"Initializing RAG pipeline with FAISS vector store...\")\n",
        "        self.embeddings = OpenAIEmbeddings()\n",
        "        documents = [Document(page_content=d) for d in docs]\n",
        "        self.db = FAISS.from_documents(documents, self.embeddings)\n",
        "        logger.info(f\"FAISS vector store created with {len(documents)} documents.\")\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 2) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Retrieves the top-k most similar documents to the query.\n",
        "\n",
        "        Args:\n",
        "            query: The user's question.\n",
        "            k: The number of documents to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            A list of LangChain Document objects.\n",
        "        \"\"\"\n",
        "        logger.debug(f\"Retrieving top-{k} documents for query: '{query}'\")\n",
        "        return self.db.similarity_search(query, k=k)\n",
        "\n",
        "    def build_context(self, query: str, k: int = 2) -> str:\n",
        "        \"\"\"\n",
        "        Retrieves and formats the top-k documents into a single context string.\n",
        "\n",
        "        Args:\n",
        "            query: The user's question.\n",
        "            k: The number of documents to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            A formatted string containing the retrieved documents.\n",
        "        \"\"\"\n",
        "        docs = self.retrieve(query, k)\n",
        "        context = \"\\n\\n\".join(d.page_content for d in docs)\n",
        "        logger.debug(\"Context built successfully.\")\n",
        "        return context"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "2DEE58cnnVxo"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}